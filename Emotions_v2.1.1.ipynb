{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4_OwNbTrWd6",
        "outputId": "dfb39de5-fbdc-4158-fd77-cd2c1c7117a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Shape of X_train: (23091, 13, 174)\n",
            "Shape of y_train: (23091, 5)\n",
            "Shape of X_test: (5773, 13, 174)\n",
            "Shape of y_test: (5773, 5)\n",
            "Epoch 1/100\n",
            "578/578 [==============================] - 14s 11ms/step - loss: 1.2505 - accuracy: 0.4121 - val_loss: 1.1452 - val_accuracy: 0.4780\n",
            "Epoch 2/100\n",
            "578/578 [==============================] - 6s 11ms/step - loss: 1.1445 - accuracy: 0.4794 - val_loss: 1.0853 - val_accuracy: 0.5086\n",
            "Epoch 3/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 1.0970 - accuracy: 0.5039 - val_loss: 1.0543 - val_accuracy: 0.5360\n",
            "Epoch 4/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 1.0646 - accuracy: 0.5267 - val_loss: 1.0143 - val_accuracy: 0.5562\n",
            "Epoch 5/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 1.0216 - accuracy: 0.5554 - val_loss: 0.9886 - val_accuracy: 0.5819\n",
            "Epoch 6/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.9895 - accuracy: 0.5727 - val_loss: 0.9337 - val_accuracy: 0.5973\n",
            "Epoch 7/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.9485 - accuracy: 0.5930 - val_loss: 0.8987 - val_accuracy: 0.6187\n",
            "Epoch 8/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.9199 - accuracy: 0.6109 - val_loss: 0.8696 - val_accuracy: 0.6387\n",
            "Epoch 9/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.8803 - accuracy: 0.6286 - val_loss: 0.8190 - val_accuracy: 0.6618\n",
            "Epoch 10/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.8519 - accuracy: 0.6443 - val_loss: 0.7928 - val_accuracy: 0.6755\n",
            "Epoch 11/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.8258 - accuracy: 0.6619 - val_loss: 0.7657 - val_accuracy: 0.6943\n",
            "Epoch 12/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.8029 - accuracy: 0.6739 - val_loss: 0.7530 - val_accuracy: 0.6943\n",
            "Epoch 13/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.7698 - accuracy: 0.6892 - val_loss: 0.7304 - val_accuracy: 0.7017\n",
            "Epoch 14/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.7585 - accuracy: 0.6945 - val_loss: 0.7089 - val_accuracy: 0.7125\n",
            "Epoch 15/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.7365 - accuracy: 0.7044 - val_loss: 0.7195 - val_accuracy: 0.7134\n",
            "Epoch 16/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.7259 - accuracy: 0.7092 - val_loss: 0.6892 - val_accuracy: 0.7294\n",
            "Epoch 17/100\n",
            "578/578 [==============================] - 6s 11ms/step - loss: 0.7095 - accuracy: 0.7189 - val_loss: 0.6725 - val_accuracy: 0.7348\n",
            "Epoch 18/100\n",
            "578/578 [==============================] - 5s 8ms/step - loss: 0.6869 - accuracy: 0.7265 - val_loss: 0.6483 - val_accuracy: 0.7426\n",
            "Epoch 19/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.6758 - accuracy: 0.7322 - val_loss: 0.6507 - val_accuracy: 0.7422\n",
            "Epoch 20/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.6694 - accuracy: 0.7353 - val_loss: 0.6364 - val_accuracy: 0.7502\n",
            "Epoch 21/100\n",
            "578/578 [==============================] - 5s 8ms/step - loss: 0.6574 - accuracy: 0.7414 - val_loss: 0.6350 - val_accuracy: 0.7519\n",
            "Epoch 22/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.6430 - accuracy: 0.7473 - val_loss: 0.6148 - val_accuracy: 0.7543\n",
            "Epoch 23/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.6260 - accuracy: 0.7511 - val_loss: 0.6240 - val_accuracy: 0.7575\n",
            "Epoch 24/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.6161 - accuracy: 0.7569 - val_loss: 0.6151 - val_accuracy: 0.7608\n",
            "Epoch 25/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.6130 - accuracy: 0.7557 - val_loss: 0.6087 - val_accuracy: 0.7664\n",
            "Epoch 26/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.6120 - accuracy: 0.7625 - val_loss: 0.6094 - val_accuracy: 0.7588\n",
            "Epoch 27/100\n",
            "578/578 [==============================] - 6s 11ms/step - loss: 0.5974 - accuracy: 0.7687 - val_loss: 0.5984 - val_accuracy: 0.7655\n",
            "Epoch 28/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5839 - accuracy: 0.7722 - val_loss: 0.5926 - val_accuracy: 0.7733\n",
            "Epoch 29/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5779 - accuracy: 0.7734 - val_loss: 0.5858 - val_accuracy: 0.7761\n",
            "Epoch 30/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.5759 - accuracy: 0.7772 - val_loss: 0.5828 - val_accuracy: 0.7748\n",
            "Epoch 31/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5744 - accuracy: 0.7776 - val_loss: 0.5818 - val_accuracy: 0.7714\n",
            "Epoch 32/100\n",
            "578/578 [==============================] - 6s 11ms/step - loss: 0.5558 - accuracy: 0.7812 - val_loss: 0.5859 - val_accuracy: 0.7690\n",
            "Epoch 33/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5518 - accuracy: 0.7868 - val_loss: 0.5736 - val_accuracy: 0.7848\n",
            "Epoch 34/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5536 - accuracy: 0.7847 - val_loss: 0.5749 - val_accuracy: 0.7764\n",
            "Epoch 35/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.5409 - accuracy: 0.7921 - val_loss: 0.5790 - val_accuracy: 0.7833\n",
            "Epoch 36/100\n",
            "578/578 [==============================] - 5s 8ms/step - loss: 0.5428 - accuracy: 0.7913 - val_loss: 0.5588 - val_accuracy: 0.7926\n",
            "Epoch 37/100\n",
            "578/578 [==============================] - 6s 10ms/step - loss: 0.5371 - accuracy: 0.7917 - val_loss: 0.5601 - val_accuracy: 0.7822\n",
            "Epoch 38/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5359 - accuracy: 0.7947 - val_loss: 0.5629 - val_accuracy: 0.7878\n",
            "Epoch 39/100\n",
            "578/578 [==============================] - 5s 9ms/step - loss: 0.5199 - accuracy: 0.8003 - val_loss: 0.5741 - val_accuracy: 0.7913\n",
            "Epoch 40/100\n",
            "578/578 [==============================] - 6s 11ms/step - loss: 0.5176 - accuracy: 0.8011 - val_loss: 0.5737 - val_accuracy: 0.7826\n",
            "Epoch 41/100\n",
            "578/578 [==============================] - 5s 8ms/step - loss: 0.5153 - accuracy: 0.8019 - val_loss: 0.5646 - val_accuracy: 0.7844\n",
            "181/181 - 1s - loss: 0.5593 - accuracy: 0.7854 - 627ms/epoch - 3ms/step\n",
            "Test accuracy: 78.54%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.config.experimental import list_physical_devices\n",
        "\n",
        "# Checking GPU availability\n",
        "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
        "\n",
        "# Loading pre-processed data from files\n",
        "X = np.load('/content/combined_features.npy')\n",
        "y = np.load('/content/combined_labels.npy')\n",
        "\n",
        "# Converting class labels to numerical values\n",
        "emotion_to_int = {emotion: idx for idx, emotion in enumerate(set(y))}\n",
        "y_int = np.array([emotion_to_int[emotion] for emotion in y])\n",
        "y_one_hot = np.zeros((len(y), len(emotion_to_int)))\n",
        "for i, emotion in enumerate(y_int):\n",
        "    y_one_hot[i, emotion] = 1\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Checking data shapes\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")\n",
        "\n",
        "# Defining the enhanced model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Using early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluating the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'Test accuracy: {test_accuracy:.2%}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the trained model (can be used after calling model.fit)\n",
        "model.save(\"/content/emotion_model.h5\")\n",
        "\n",
        "print(\"Model saved as '/content/emotion_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3fdwbXssQNh",
        "outputId": "38a409dc-d477-44c9-bcb4-603daa5a2ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as '/content/emotion_model.h5'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model weights\n",
        "model.save_weights(\"/content/emotion_model_weights.h5\")\n",
        "\n",
        "# For loading weights\n",
        "# model.load_weights(\"/content/emotion_model_weights.h5\")"
      ],
      "metadata": {
        "id": "rsxFax4n0E5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Exporting the model file\n",
        "files.download('/content/emotion_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "akazR-ct8xCp",
        "outputId": "dc3f1d58-ed8a-4f68-9f3c-1dcdf0634116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1bb5800f-c05e-4779-a26a-085bdb0e491c\", \"emotion_model.h5\", 5084720)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the model file\n",
        "files.download('/content/emotion_model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L-6QlgrU9AkZ",
        "outputId": "6b546f43-7041-4139-cd4b-ca48f8699dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8a6dccec-4744-4f71-bf0c-c835e3b61381\", \"emotion_model_weights.h5\", 1702416)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model in the new Keras format\n",
        "model.save(\"/content/emotion_model.keras\")"
      ],
      "metadata": {
        "id": "MdPlQqf29Rft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the model file\n",
        "files.download('/content/emotion_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UZux7TlI9df3",
        "outputId": "eee9b541-e542-497f-d843-4cd55e4de1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bd6490c9-5a24-448c-ba87-e45c1495175f\", \"emotion_model.keras\", 5074286)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Loading the model\n",
        "model_path = 'emotion_model.keras'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Dictionary for decoding emotions\n",
        "emotion_to_int = {0: 'angry', 1: 'happy', 2: 'neutral', 3: 'sad', 4: 'surprised'}\n",
        "# Reverse: {v: k for k, v in emotion_to_int.items()}\n",
        "int_to_emotion = {v: k for k, v in emotion_to_int.items()}\n",
        "\n",
        "# Function for preprocessing audio files\n",
        "def preprocess_audio(file_path, max_pad_len=174):\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
        "    if mfccs.shape[1] < max_pad_len:\n",
        "        pad_width = max_pad_len - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfccs = mfccs[:, :max_pad_len]\n",
        "    return mfccs\n",
        "\n",
        "# Path to audio files\n",
        "audio_files = ['Surprised.wav', 'Sad.wav']\n",
        "audio_dir = './'\n",
        "\n",
        "# Preprocessing and predictions\n",
        "for file_name in audio_files:\n",
        "    file_path = os.path.join(audio_dir, file_name)\n",
        "    mfcc_features = preprocess_audio(file_path)\n",
        "    mfcc_features = np.expand_dims(mfcc_features, axis=0)  # Adding a batch dimension\n",
        "    prediction = model.predict(mfcc_features)\n",
        "    predicted_emotion = emotion_to_int[np.argmax(prediction)]\n",
        "    print(f\"{file_name}: {predicted_emotion}\")\n",
        "\n",
        "# Additionally, if probabilities are needed\n",
        "    probabilities = prediction[0]\n",
        "    emotion_probabilities = {emotion_to_int[i]: prob for i, prob in enumerate(probabilities)}\n",
        "    print(f\"Probabilities for {file_name}: {emotion_probabilities}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiWgFqZiB6-4",
        "outputId": "93cf2782-3eb3-4c5b-e2f7-8b7d5696b7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 897ms/step\n",
            "Surprised.wav: surprised\n",
            "Probabilities for Surprised.wav: {'angry': 6.5860775e-05, 'happy': 0.07020777, 'neutral': 0.011884412, 'sad': 0.1126476, 'surprised': 0.8051943}\n",
            "\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Sad.wav: sad\n",
            "Probabilities for Sad.wav: {'angry': 2.349024e-06, 'happy': 0.000814713, 'neutral': 0.0006074288, 'sad': 0.9939521, 'surprised': 0.0046234373}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}